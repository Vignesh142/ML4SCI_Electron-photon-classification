{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2719eb14-3a46-46af-9d62-917f3c81ab0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21e8312e-692d-4066-843c-71c9f9a0ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, models\n",
    "# importing keras layers for cnn\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "# splitting the data to train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aaed60-b19a-40cd-92bc-89985ec6b7c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LoadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80013716-45a6-4a5b-877c-be7637f5e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "f1=h5py.File('SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5','r')\n",
    "f2=h5py.File('SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0ea58-740f-4ed8-b0a2-020db3760b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photon data:  ['X', 'y']\n",
      "Electron data:  ['X', 'y']\n"
     ]
    }
   ],
   "source": [
    "print(\"Photon data: \",list(f1.keys()))\n",
    "print(\"Electron data: \",list(f2.keys()))\n",
    "X_photon=np.array(f1.get('X'))\n",
    "X_electron=np.array(f2.get('X'))\n",
    "y_photon=np.array(f1.get('y'))\n",
    "y_electron=np.array(f2.get('y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fc6459-6c7c-4d45-910e-c23c45e8ba2d",
   "metadata": {},
   "source": [
    "### Visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a5f808-9136-4b8a-b6a7-9aa548f6c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#photon sample data for training\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X_photon[0,:,:,0])\n",
    "plt.title('Energy')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(X_photon[0,:,:,1])\n",
    "plt.title('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce38d72-379b-4285-8cc6-a6d8cc799521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#electron sample data for training\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X_electron[0,:,:,0])\n",
    "plt.title('Energy')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(X_electron[0,:,:,1])\n",
    "plt.title('Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7b45fc-3f58-43f8-bbd9-fe2d50c896cc",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b03464-2f19-4bcb-aab2-3d84a2ae89c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.concatenate((X_photon,X_electron),axis=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ad8d9-3603-4031-bfb5-f58d243724c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.concatenate((y_photon,y_electron),axis=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c305c6-6f64-4b67-993f-4c2817c64ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53badca8-bb67-4ccd-9ca3-ad6fa1c803a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val= train_test_split(X_train,y_train,test_size=0.1,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bbdcfd-4223-4f0e-b189-a48a0c0b9620",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182f3f3-5ed5-4f1b-8d69-fd372c57955a",
   "metadata": {},
   "source": [
    "# Prepare CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f794d-162d-4f01-860b-f791d2889b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(32,32,2)))\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu',padding=\"same\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu',padding=\"same\"))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu',padding=\"same\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu',padding=\"same\"))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu',padding=\"same\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a465b39-062e-4e89-99e6-f6e80b71881b",
   "metadata": {},
   "source": [
    "#### Loss function and optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9f9b01-96d1-4a4a-8e79-69bff231a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389e7ee2-d241-490c-9dfe-acf904373c11",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c85b7b-c88f-469c-867a-25f57f0e9b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist=model.fit(X_train,y_train,batch_size=40,epochs=10,validation_data=(X_val,y_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a85c384-1b03-4b1a-88ce-23eecfec9897",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0df2d0-01d9-4f12-b0e1-d40070a97885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=model.predict(X_test)\n",
    "# l=y_pred.len()\n",
    "# for i in range(l):\n",
    "#     y_pred[i]=round(y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07891be-a834-4dc7-beb7-a1ed368fb8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist.history\n",
    "roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b151350-fdd1-4d2b-b481-528e43c7fb1f",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb833fb-9c86-4597-af26-4b8b31a6800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527ee4ab-35e4-4525-8ee4-1480af3d9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models','photonelectronModel.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbde8e9b-edd7-44fc-bfa5-e4169dfae8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.join('models','photonelectronModels.h5')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d63424-db32-4786-8f03-b299c371ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model= load_model(os.path.join('models','photonelectronModel.h5'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72cb992-22e0-48b8-aee1-04c4cefd4591",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c0dad-d0a0-491f-9f71-9b3da394e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=model.predict(X_test)\n",
    "y_pred=new_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf2eb1-7b1c-49ff-8adb-995c7d6f384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_int=(np.rint(y_pred)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc63fd6c-348e-4a68-a8d0-1ee86ec7508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score=roc_auc_score(y_test,y_pred)\n",
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1323c102-4d4b-4c00-a993-ff9996d99617",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test,  y_pred)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc_score))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046cb737-6a88-4c84-8cda-685d9d17c898",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pytorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b16133-1ce2-4f7a-9326-9a8e75c64642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e973261e-e9cd-4d66-a32e-e60ba5defd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb01f9ca-535d-4a19-a053-bfead535098c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchmetrics.classification import BinaryAUROC\n",
    "\n",
    "torch.__version__\n",
    "# torchvision.__version__\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f5e86d-2fdb-43d5-abf9-08eb1f60e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "f1=h5py.File('SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5','r')\n",
    "f2=h5py.File('SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4704c0f1-c186-4eea-aaee-9f05a976fb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photon data:  ['X', 'y']\n",
      "Electron data:  ['X', 'y']\n"
     ]
    }
   ],
   "source": [
    "print(\"Photon data: \",list(f1.keys()))\n",
    "print(\"Electron data: \",list(f2.keys()))\n",
    "X_photon=np.array(f1.get('X'))\n",
    "X_electron=np.array(f2.get('X'))\n",
    "y_photon=np.array(f1.get('y'))\n",
    "y_electron=np.array(f2.get('y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f6de63-59c1-4f61-81b8-55d6931d434a",
   "metadata": {},
   "source": [
    "# Split data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfcf8a40-d783-40d6-a553-5b63578ad0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.concatenate((X_photon,X_electron),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d40c0e38-d949-4d02-a8f4-dc196d733842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498000, 2, 32, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.transpose(X,(0,3,1,2))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7be5bf42-d835-461f-8942-ca9f39281e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.concatenate((y_photon,y_electron),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5545b135-c336-4c7b-ab6a-2bf4c851189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2af3755b-5ae5-477a-a7a7-3268ae39ec7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398400, 2, 32, 32), (99600, 2, 32, 32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5749210-4642-42b6-86c9-237d3e9beb37",
   "metadata": {},
   "source": [
    "## Prepare DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f0c0e65-3efe-4489-bc99-4989511a769d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x0000023131C88E80>, <torch.utils.data.dataloader.DataLoader object at 0x0000023131C88AC0>)\n",
      "Length of train dataloader: 12450 batches of 32\n",
      "Length of test dataloader: 3113 batches of 32\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from torch  import Tensor\n",
    "BATCH_SIZE=32\n",
    "\n",
    "data_train=TensorDataset(Tensor(X_train[:,:,:,:]),Tensor(y_train[:]))# training\n",
    "data_test= TensorDataset(Tensor(X_test[:,:,:,:]),Tensor(y_test[:]))#test\n",
    "\n",
    "train_dataloader=DataLoader(data_train,batch_size=BATCH_SIZE,shuffle=False)\n",
    "test_dataloader=DataLoader(data_test,batch_size=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "120a9317-cfad-4e0f-90e9-0a2a43a45059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 32, 32]), torch.Size([32]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out what's inside the training dataloader\n",
    "# training_batch,training_label= next(iter(train_dataloader_ene))\n",
    "# training_batch.shape,training_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8cc220e3-443d-494c-80a4-307bdd8c70d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten_model=nn.Flatten()\n",
    "# x=flatten_model(training_batch[0])\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1722b74-00e1-495d-ad72-1f451bc0f522",
   "metadata": {},
   "source": [
    "## Functions- Timing, Train and Test loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36af5f0e-f872-420d-b47f-c59d83a191c8",
   "metadata": {},
   "source": [
    "### Timing experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f7b1a0e-db51-4fec-bbcf-ff35edc72dae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0f9a15-cfdc-4141-a126-d8d1657ce92c",
   "metadata": {},
   "source": [
    "### Train and Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "802a185b-3e88-4cb7-b3e9-a249ede1f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device = device):\n",
    "    train_loss, train_acc, running_loss = 0, 0, 0\n",
    "    c=0\n",
    "    print(\"dataloaderLen: \",len(data_loader))\n",
    "    for batch, (X,y) in enumerate(data_loader):\n",
    "        c=c+1\n",
    "        y = y.unsqueeze(1).float()\n",
    "        # Send data to CPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # X,y= data\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "        # print(y_pred.squeeze(dim=1),y.squeeze(dim=1))\n",
    "    \n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        running_loss+= loss\n",
    "        acc=BinaryAUROC(thresholds=None)\n",
    "        train_acc += acc(y_pred.squeeze(dim=1),y.squeeze(dim=1))\n",
    "        \n",
    "        if batch % 100 == 99:    # print every 100 mini-batches\n",
    "            print(f'{batch + 1:5d} loss: {running_loss / 100:.5f}')\n",
    "            running_loss = 0.0\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "        # if c==500:\n",
    "            # break\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.5f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c62780d6-6b02-4367-9fee-fe38383fda9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device = device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    c=0\n",
    "    # Turn on inference context manager\n",
    "    with torch.no_grad():\n",
    "        for X,y in data_loader:\n",
    "            # Send data to CPU\n",
    "            y = y.unsqueeze(1).float()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            c+=1\n",
    "            \n",
    "            model.eval() # put model in eval mode\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            acc=BinaryAUROC(thresholds=None)\n",
    "            test_acc += acc(test_pred.squeeze(dim=1),y.squeeze(dim=1))\n",
    "        \n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.5f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ab76a7-1ce1-4e02-a6a9-0c84a34d505f",
   "metadata": {},
   "source": [
    "## Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10d92e97-2124-46ce-939c-4ba9f644c0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (block_1): Sequential(\n",
       "    (0): Conv2d(2, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block_2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=640, out_features=1, bias=True)\n",
       "    (2): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3, # how big is the square that's going over the image?\n",
    "                      stride=1, # default\n",
    "                      padding=1),# options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # default stride value is same as kernel_size\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
    "            nn.Linear(in_features=640,\n",
    "                      out_features=output_shape),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x: torch.Tensor):\n",
    "        x=self.block_1(x)\n",
    "        x=self.block_2(x)\n",
    "        x=self.classifier(x)\n",
    "        return x\n",
    "torch.manual_seed(30)\n",
    "model_= Model(input_shape=2,hidden_units=10,output_shape=1).to(device)\n",
    "model_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b1cce6-f5c2-4269-96a0-f3d55c228bd5",
   "metadata": {},
   "source": [
    "#### Sample Conv2d and MaxPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0186e95b-cae1-4846-9668-815e3ca31acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 15, 15])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating sample conv2d layer\n",
    "training_batch,label= next(iter(train_dataloader_ene))\n",
    "training_batch.shape\n",
    "torch.manual_seed(30)\n",
    "\n",
    "test_img= training_batch[0]\n",
    "test_img=test_img.unsqueeze(dim=0)\n",
    "# test_img.shape\n",
    "conv_layer = nn.Conv2d(in_channels=1,\n",
    "                       out_channels=10,\n",
    "                       kernel_size=3,\n",
    "                       stride=2,\n",
    "                       padding=0) # also try using \"valid\" or \"same\" here \n",
    "test_img_through_conv=conv_layer(test_img)\n",
    "test_img_through_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7985b094-f58d-4b9a-b79c-73812c7c7f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 7, 7])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating sample nn.MaxPoo2d() layer\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "test_img_through_conv_maxpool = max_pool_layer(test_img_through_conv)\n",
    "test_img_through_conv_maxpool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8037b844-daa6-476d-a6ae-14f449e5d9f5",
   "metadata": {},
   "source": [
    "### Setup Loss Func and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c723368-9e2f-48ae-a67d-777c1b8db723",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCELoss()\n",
    "optimizer= torch.optim.Adam(params=model_.parameters(),lr=0.07)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f3c9a-2a39-4803-a16b-e57971ec12b2",
   "metadata": {},
   "source": [
    "### Accuracy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e608b07-b059-425d-bed7-f44a58247702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    # print(correct,len(y_pred))\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2bf4a6-5e8c-4154-bd46-a0a13a8399a7",
   "metadata": {},
   "source": [
    "### Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efd8e05d-265e-4c95-8118-090ef8b51cbc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b92ea59d0b42d7a7e46d08d3ce7ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n",
      "dataloaderLen:  12450\n",
      "  100 loss: 0.23758\n",
      "  200 loss: 0.23145\n",
      "  300 loss: 0.23138\n",
      "  400 loss: 0.23173\n",
      "  500 loss: 0.23182\n",
      "  600 loss: 0.23176\n",
      "  700 loss: 0.23103\n",
      "  800 loss: 0.23190\n",
      "  900 loss: 0.23140\n",
      " 1000 loss: 0.23142\n",
      " 1100 loss: 0.23163\n",
      " 1200 loss: 0.23152\n",
      " 1300 loss: 0.23174\n",
      " 1400 loss: 0.23178\n",
      " 1500 loss: 0.23167\n",
      " 1600 loss: 0.23153\n",
      " 1700 loss: 0.23159\n",
      " 1800 loss: 0.23141\n",
      " 1900 loss: 0.23154\n",
      " 2000 loss: 0.23155\n",
      " 2100 loss: 0.23142\n",
      " 2200 loss: 0.23136\n",
      " 2300 loss: 0.23138\n",
      " 2400 loss: 0.23141\n",
      " 2500 loss: 0.23150\n",
      " 2600 loss: 0.23162\n",
      " 2700 loss: 0.23145\n",
      " 2800 loss: 0.23130\n",
      " 2900 loss: 0.23187\n",
      " 3000 loss: 0.23270\n",
      " 3100 loss: 0.23087\n",
      " 3200 loss: 0.23173\n",
      " 3300 loss: 0.23151\n",
      " 3400 loss: 0.23143\n",
      " 3500 loss: 0.23208\n",
      " 3600 loss: 0.23126\n",
      " 3700 loss: 0.23150\n",
      " 3800 loss: 0.23145\n",
      " 3900 loss: 0.23154\n",
      " 4000 loss: 0.23111\n",
      " 4100 loss: 0.23157\n",
      " 4200 loss: 0.23133\n",
      " 4300 loss: 0.23156\n",
      " 4400 loss: 0.23117\n",
      " 4500 loss: 0.23150\n",
      " 4600 loss: 0.23174\n",
      " 4700 loss: 0.23165\n",
      " 4800 loss: 0.23168\n",
      " 4900 loss: 0.23140\n",
      " 5000 loss: 0.23137\n",
      " 5100 loss: 0.23140\n",
      " 5200 loss: 0.23153\n",
      " 5300 loss: 0.23236\n",
      " 5400 loss: 0.23142\n",
      " 5500 loss: 0.23138\n",
      " 5600 loss: 0.23147\n",
      " 5700 loss: 0.23228\n",
      " 5800 loss: 0.23137\n",
      " 5900 loss: 0.23136\n",
      " 6000 loss: 0.23121\n",
      " 6100 loss: 0.23164\n",
      " 6200 loss: 0.23156\n",
      " 6300 loss: 0.23226\n",
      " 6400 loss: 0.23162\n",
      " 6500 loss: 0.23153\n",
      " 6600 loss: 0.23150\n",
      " 6700 loss: 0.23197\n",
      " 6800 loss: 0.23152\n",
      " 6900 loss: 0.23168\n",
      " 7000 loss: 0.23152\n",
      " 7100 loss: 0.23174\n",
      " 7200 loss: 0.23144\n",
      " 7300 loss: 0.23154\n",
      " 7400 loss: 0.23123\n",
      " 7500 loss: 0.23138\n",
      " 7600 loss: 0.23184\n",
      " 7700 loss: 0.23132\n",
      " 7800 loss: 0.23202\n",
      " 7900 loss: 0.23136\n",
      " 8000 loss: 0.23170\n",
      " 8100 loss: 0.23149\n",
      " 8200 loss: 0.23244\n",
      " 8300 loss: 0.23178\n",
      " 8400 loss: 0.23166\n",
      " 8500 loss: 0.23110\n",
      " 8600 loss: 0.23131\n",
      " 8700 loss: 0.23133\n",
      " 8800 loss: 0.23109\n",
      " 8900 loss: 0.23138\n",
      " 9000 loss: 0.23168\n",
      " 9100 loss: 0.23161\n",
      " 9200 loss: 0.23145\n",
      " 9300 loss: 0.23111\n",
      " 9400 loss: 0.23190\n",
      " 9500 loss: 0.23212\n",
      " 9600 loss: 0.23129\n",
      " 9700 loss: 0.23127\n",
      " 9800 loss: 0.23167\n",
      " 9900 loss: 0.23182\n",
      "10000 loss: 0.23162\n",
      "10100 loss: 0.23113\n",
      "10200 loss: 0.23139\n",
      "10300 loss: 0.23143\n",
      "10400 loss: 0.23138\n",
      "10500 loss: 0.23145\n",
      "10600 loss: 0.23167\n",
      "10700 loss: 0.23172\n",
      "10800 loss: 0.23183\n",
      "10900 loss: 0.23185\n",
      "11000 loss: 0.23135\n",
      "11100 loss: 0.23204\n",
      "11200 loss: 0.23174\n",
      "11300 loss: 0.23131\n",
      "11400 loss: 0.23193\n",
      "11500 loss: 0.23148\n",
      "11600 loss: 0.23128\n",
      "11700 loss: 0.23189\n",
      "11800 loss: 0.23125\n",
      "11900 loss: 0.23159\n",
      "12000 loss: 0.23115\n",
      "12100 loss: 0.23187\n",
      "12200 loss: 0.23134\n",
      "12300 loss: 0.23137\n",
      "12400 loss: 0.23141\n",
      "Train loss: 0.69482 | Train accuracy: 0.50001%\n",
      "Train time on cpu: 2728.103 seconds\n"
     ]
    }
   ],
   "source": [
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.manual_seed(30)\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_model = timer()\n",
    "\n",
    "# Train and test model\n",
    "epochs = 1\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader,\n",
    "        model=model_,\n",
    "        loss_fn=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device)\n",
    "\n",
    "train_time_end_model = timer()\n",
    "total_train_time_model = print_train_time(start=train_time_start_model,\n",
    "                                           end=train_time_end_model,\n",
    "                                           device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e92a5094-d136-42d1-9535-1f1cf0b4c7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.69393 | Test accuracy: 0.50000%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_step(data_loader=test_dataloader,\n",
    "    model=model_,\n",
    "    loss_fn=criterion,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb5799-c10b-4b7a-bb3e-373e7a296a51",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6604f6d1-898e-4892-a01d-ae20254d5c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model to: models\\pytorch_model_electron_photon_c(1).pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, # create parent directories if needed\n",
    "                 exist_ok=True # if models directory already exists, don't error\n",
    ")\n",
    "MODEL_NAME = \"pytorch_model_electron_photon_c(1).pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "print(f\"Saving Model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_.state_dict(),f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5ca4a8a-f0b0-4aac-b003-58f660bfa711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (block_1): Sequential(\n",
       "    (0): Conv2d(2, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block_2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=640, out_features=1, bias=True)\n",
       "    (2): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model= Model(input_shape=2,hidden_units=10,output_shape=1)\n",
    "# Load in the saved state_dict()\n",
    "loaded_model.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
    "\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc9f449d-4cd6-405b-a224-9dbdbcd8c980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.69393 | Test accuracy: 0.50000%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_step(data_loader=test_dataloader,\n",
    "    model=loaded_model,\n",
    "    loss_fn=criterion,\n",
    "    device=device\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computervision",
   "language": "python",
   "name": "computervision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
